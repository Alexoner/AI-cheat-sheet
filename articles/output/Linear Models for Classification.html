<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="Linear Models for Classification">Linear Models for Classification</h1>
<p>The goal in classification is to take an input vector <span class="math inline">\(\vec{x}\)</span> and to assign it to one of <span class="math inline">\(K\)</span> discrete classes <span class="math inline">\(\mathcal{C}_k\)</span> where <span class="math inline">\(K = 1,...,K\)</span>.The input space is thereby divided into <strong>decision regions</strong> whose boundaries are called <strong>decision boundaries</strong> or <strong>decision surfaces</strong>.Data sets whose classes can be separated exactly by linear decision surfaces are said to be <strong>linearly separable</strong>.</p>
<p>In Chapter 1,we identified three distinct approaches to the classification problem.The simplest involves constructing a <strong>discriminant function</strong> that directly assigns each vector x to a specific class. A more powerful approach, however, models the <strong>conditional probability distribution</strong> <span class="math inline">\(p(C_k|x)\)</span> in an <strong>inference</strong> stage, and then subsequently uses this distribution to make optimal <strong>decisions</strong>. By separating inference and decision, we gain numerous benefits, as discussed in [chapter:Introduction]. There are two different approaches to determining the conditional probabilities <span class="math inline">\(p(C_k|x)\)</span>. One technique is to model them <strong>directly</strong>, for example by representing them as parametric models and then optimizing the parameters using a training set. Alternatively, we can adopt a generative approach in which we model the <strong>class-conditional densities</strong> given by p(x|Ck), together with the <strong>prior probabilities</strong> p(Ck) for the classes, and then we compute the required posterior probabilities using Bayes’ theorem <span class="math display">\[p(\mathcal{C}_k|\vec{x}) = \dfrac{p(\vec{x}\mathcal{C}_k)p(\mathcal{C}_k)}{p(\vec{x})}\]</span></p>
<p>In the linear regression models considered in Chapter 3, the model prediction y(x,w) was given by a linear function of the parameters w. In the simplest case, the model is also linear in the input variables and therefore takes the form y(x) = <span class="math inline">\(\vec{w}^Tx+w_0\)</span>, so that y is a real number. For classification problems, however, we wish to predict discrete class labels, or more generally posterior probabilities that lie in the range (0, 1). To achieve this, we consider a generalization of this model in which we transform the linear function of w using a nonlinear function <span class="math inline">\(f( · )\)</span> so that <span class="math display">\[y(\vec{x}) = f(\vec{w}^T\vec{x} + w_0)\]</span> In the machine learning literature <span class="math inline">\(f(\cdot)\)</span> is known as an <strong>activation function</strong>,whereas its inverse is called a <strong>link function</strong> in the statistics literature.The decision surfaces correspond to y(x) = constant, so that <span class="math inline">\(\vec{w}^T\vec{x} + w_0 = constant\)</span> and hence the decision surfaces are linear functions of <span class="math inline">\(\vec{x}\)</span>, even if the function <span class="math inline">\(f(·)\)</span> is nonlinear. For this reason, the class of models described by (4.3) are called <strong>generalized linear models</strong> (McCullagh and Nelder,1996).However,in contrast to the models used for regression,they are no longer linear in the parameters due to the presence of the nonlinear function <span class="math inline">\(f(\cdot)\)</span>.</p>
<h2 id="discriminant-functions">Discriminant Functions</h2>
<p>A discriminant is a function that takes an input vector <span class="math inline">\(\vec{x}\)</span> and assigns it to be one of <span class="math inline">\(K\)</span> classes,denoted <span class="math inline">\(\mathcal{C}_k\)</span>.</p>
<h3 id="two-classes">Two classes</h3>
<p>Linear discriminant function <span class="math display">\[\begin{aligned}
y(\vec{x}) = \vec{x}^T\vec{x}+w_0\end{aligned}\]</span> where <span class="math inline">\(\vec{w}\)</span> is called a <strong>weight vector</strong>,and <span class="math inline">\(w_0\)</span> is <span class="math inline">\(bias\)</span>.The negative of the bias is sometimes called <strong>threshold</strong>.</p>
<p>The value of <span class="math inline">\(y(\vec{x})\)</span> gives a signed measure of the perpendicular distance <span class="math inline">\(r\)</span> of point <span class="math inline">\(\vec{x}\)</span> from the decision surface.Consider an arbitrary point <span class="math inline">\(\vec{x}\)</span> and let <span class="math inline">\(\vec{x}_\perp\)</span> be its orthogonal projection onto the decision surface,then <span class="math display">\[\begin{aligned}
\vec{x} &amp;= \vec{x}_\perp + r\dfrac{\vec{w}}{\parallel\vec{w}\parallel} \\\end{aligned}\]</span> Multiplying both sides by <span class="math inline">\(\vec{w}^T\)</span> and adding <span class="math inline">\(\vec{w}_0\)</span>, <span class="math display">\[\begin{aligned}
\label{eqn:distance from point to hyperplane}
y(\vec{x}) &amp;= y(\vec{x}_{\perp}) + r\dfrac{\vec{w}\cdot\vec{w}}{\parallel\vec{w}\parallel} \\
&amp;= r\parallel\vec{w}\parallel\\
\therefore
r &amp;= \dfrac{y(\vec{x})}{\parallel\vec{w}\parallel}\end{aligned}\]</span></p>
<h3 id="multiple-classes">Multiple classes</h3>
<p>Consider the extension of linear discriminants to <span class="math inline">\( K &gt;2\)</span> classes,building a <span class="math inline">\(K\)</span>-class discriminants by combining a number of two-class discriminant functions on which leads to some serious difficulties(Duda and Hart,1973).</p>
<p>Consider the use of <span class="math inline">\(K-1\)</span> classifier each of which solves a two-class problem of separating points int particular class <span class="math inline">\(\mathcal{C}_k\)</span> from points not in that class.This is known as a <strong>one-versus-the-rest</strong> classifier.An alternative is to introduce <span class="math inline">\(K(K-1)/2\)</span> binary discriminant functions,one for every possible pair classes.This is known as a <strong>one-versus-one</strong> classifier.Both of these two approaches run into the problem of ambiguous regions.We can avoid these difficulties by considering a single <span class="math inline">\(K\)</span>-class discriminant comprising <span class="math inline">\(k\)</span> linear functions of the form <span class="math display">\[y_k(\vec{x}) = \vec{w_k}^T\vec{x}+w_{k0}\]</span> and then assigning a point <span class="math inline">\(\vec{x}\)</span> to class <span class="math inline">\(\mathcal{C}_k\)</span> if <span class="math inline">\(y_k(\vec{x}) &gt; y_j(\vec{x})\)</span> for all <span class="math inline">\(j \neq k\)</span>.The decision boundary between class <span class="math inline">\(\mathcal{C}_k\)</span> and <span class="math inline">\(\mathcal{C}_j\)</span> is therefore given by <span class="math inline">\(y_k(\vec{x}) = y_j(\vec{x})\)</span> and hence corresponds to a <span class="math inline">\((D-1)\)</span>-dimensional hyperplane defined by <span class="math display">\[(\vec{w_k}-\vec{w_j})^T + (w_{k0}-w_{j0}) = 0\]</span> The decision regions of such a discriminant are always singly connected and convex.</p>
<h3 id="least-squares-for-classification">Least squares for classification</h3>
<p>Even as a discriminant function(where we use it to make decisions directly and dispense with any probabilistic interpretation)it suffers from some severe problems.Least-squares solutions lack robustness to outliers,and this applies equally to the classification application.Additional points(outliers) produce a significant change in the location of the decision boundary.The sum-of-squares error function penalizes predictions that are ’too correct’ in that they lie a long way on the correct side of the decision boundary.More than lack of robustness,least-squares solutions may gives poor results on classification problems.</p>
<p>The failure of least squares lies in the fact that it corresponds to maximum likelihood under the assumption of a Gaussian conditional distribution,whereas binary target vectors clearly have a distribution that is far from Gaussian(a Bernoulli).</p>
<h3 id="fishers-linear-discriminant">Fisher’s linear discriminant</h3>
<h4 id="representation">representation</h4>
<p>One way to view a linear classification model is in terms of dimensionality reduction.Consider first the case of two classes,and suppose we take the <span class="math inline">\(D-dimensional\)</span> input vector <span class="math inline">\(\vec{x}\)</span> and project it down to one dimension using <span class="math display">\[\label{eqn:Fisher LDA projection}
y = \vec{w}^T\vec{x}.\]</span> If we place a threshold on <span class="math inline">\(y\)</span> and classify <span class="math inline">\(y \geq -w_0\)</span> as class <span class="math inline">\(\mathcal{C_1}\)</span>,and otherwise class <span class="math inline">\(\mathcal{C_2}\)</span>,then we obtain our standard linear classifier discussed in the previous section.</p>
<h4 id="evaluation">evaluation</h4>
<p>By adjusting the components of the weight vector <span class="math inline">\(\vec{w}\)</span>,we can select a projection that maximizes the class separation.To begin with,consider a two-class problem in which there are <span class="math inline">\(N_1\)</span> points of class <span class="math inline">\(\mathcal{C_1}\)</span> and <span class="math inline">\(N_2\)</span> points of class <span class="math inline">\(\mathcal{C_2}\)</span>,so that the mean vectors of the two classes are given by <span class="math display">\[\vec{m_1} = \dfrac{1}{N_1} \sum_{n\in \mathcal{C_1}}{\vec{x_n}},\vec{m_1} = \dfrac{1}{N_2}\sum_{n\in \mathcal{C_2}}\vec{x_n}\]</span> The simplest measure of the separation of the classes,when projected onto <span class="math inline">\(\vec{w}\)</span>,is the separation of the projected class means.This suggests that we might choose <span class="math inline">\(\vec{w}\)</span> so as to maximize <span class="math display">\[m_2 - m_1 = \vec{x}^T(\vec{m_2}-\vec{m_1})\]</span> where<span class="math display">\[m_k = \vec{w}^T\vec{m_k}\]</span> is the mean of the projected data from class <span class="math inline">\(\mathcal{C_k}\)</span>.However this expression can be makde arbitrarily large simply by increasing the magnitude of <span class="math inline">\(\vec{w}\)</span>.To solve this,we could constrain <span class="math inline">\(\vec{2}\)</span> to have unit length,so that <span class="math inline">\(\sum_{i}{w_i^2}=1\)</span>.Using a Lagrange multiplier to perform the constrained maximization,we then find that <span class="math inline">\(\vec{w} \propto (\vec{m_2} - \vec{m_1})\)</span>.There is still a problem with this approach that the projected data have considerable overlap for strongly nondiagonal convariances of the class distributions.</p>
<h4 id="optimization">optimization</h4>
<p>The idea proposed by Fisher is to <strong>maximize a function that will give a large separation between the projected class means while also giving a small variance within each class,thereby minimizing the class overlap</strong>.The projection formula [eqn:Fisher LDA projection] transforms the set of labelled data points in <span class="math inline">\(\vec{x}\)</span> into a labelled set in the one-dimensional space <span class="math inline">\(y\)</span>.The within-class variance of the transformed data from class <span class="math inline">\(\mathcal{C_k}\)</span> is therefore given by <span class="math display">\[s_k^2 = \sum_{n\in \mathcal{C_k}}(y_n-m_k)^2\]</span> where<span class="math display">\[y_n = \vec{w}^T\vec{x_n}\]</span> We can define the total within-class variance for the whole data set to be simply <span class="math inline">\(s_1^2+s_2^2\)</span>.The Fisher criterion is defined to be the ratio of the between-class variance to the within-class variance and is given by <span class="math display">\[J(\vec{w}) = \dfrac{(m_2-m_1)^2}{s_1^2+s_2^2}\]</span></p>
<p>We can make the dependence on explicit by rewrite the Fisher criterion in the form <span class="math display">\[\label{eqn:Fisher criterion}
J(\vec{w}) = \dfrac{\vec{w}^T\vec{S_B}\vec{w}}{\vec{w}^T\vec{S_W}\vec{w}}\]</span> where <span class="math inline">\(\vec{S_B}\)</span> is the <span class="math inline">\(between-class\)</span> covariance matrix,given by <span class="math display">\[\label{eqn:Fisher between-class covariance matrix}
\vec{S_B} = (\vec{m_2}-\vec{m_1})(\vec{m_2}-\vec{m_1})^T\]</span> so <span class="math display">\[\vec{w}^T\vec{S_B}\vec{w} = \vec{w} ^T(\vec{m_2} - \vec{m_1})(\vec{m_2}-\vec{m_1})^T\vec{w} = (m_2-m_1)(m_2-m_1)\]</span> and <span class="math inline">\(\vec{S_W}\)</span> is the total <span class="math inline">\(within-class\)</span> covariance matrix,given by <span class="math display">\[\vec{S_W} = \sum_{\mathcal{C}}\sum_{n\in \mathcal{C}_1}(\vec{x_n} - \vec{m_1})(\vec{x_n}-\vec{m_1})^T\]</span> so <span class="math display">\[\vec{w}^T\vec{S_W}\vec{w} = \sum_{\mathcal{C}_k}\sum_{n\in \mathcal{C}_k}{\vec{w}^T(\vec{x_n}-\vec{m_k})(\vec{x_n}-\vec{m_k})^T} = \sum_{\mathcal{C}_i}\sum_{n \in \mathcal{C}_k}(y_n-m_k)^2\]</span> Differentiating [eqn:Fisher criterion] with respect to <span class="math inline">\(\vec{w}\)</span>,we find that <span class="math inline">\(J(\vec{w})\)</span> is maximized when <span class="math display">\[{(\vec{w}^T\vec{S_B}\vec{w})\vec{S_W}\vec{w}} = (\vec{w}^T\vec{S_W}\vec{w})\vec{S_B}\vec{w}\]</span> Rewriting this as <span class="math display">\[\label{eqn:Fisher generalized eigenvalue}
\vec{S_B}\vec{w} = \lambda\vec{S_W}\vec{w}\]</span> where <span class="math display">\[\lambda = \dfrac{(\vec{w}^T\vec{S_B}\vec{w})}{(\vec{w}^T\vec{S_W}\vec{w})}\]</span> which is called a <strong>generalized eigenvalue</strong> problem solution.</p>
<p><span class="math display">\[\begin{aligned}
\because\begin{cases}
    \dfrac{\partial}{\partial x}\dfrac{f(x)}{g(x)} 
    = \dfrac{f&#39;g-fg&#39;}{g^2}, \text{where } f^\prime 
    = \dfrac{\partial f(x)}{\partial x} \text{ and } g&#39; 
    = \dfrac{\partial g(x)}{\partial x} \\ 
    \dfrac{\partial}{\partial \vec{x}} \vec{x}^T\vec{A}\vec{x} = (\vec{A}+\vec{A}^T)\vec{x}
\end{cases} \\
\therefore\end{aligned}\]</span></p>
<p><span class="math display">\[\begin{aligned}
\dfrac{\partial}{\partial \vec{w}}J(\vec{w}) &amp; =  \dfrac{2\vec{S_B}\vec{w}(\vec{w}^T\vec{S_W}\vec{w})-(\vec{w}^T\vec{S_B}\vec{w})\vec{S_W}\vec{w}}{(\vec{w}^T\vec{S_W}\vec{w})^2}\end{aligned}\]</span></p>
<p>Setting the derivative to zero,we can get the result.</p>
<p>In particular,since <span class="math display">\[\lambda\vec{w} = \vec{S_W}(\vec{m_2}-\vec{m_1})(m_2-m_1)\]</span> Multiply both sides of [eqn:Fisher generalized eigenvalue] by <span class="math inline">\(\vec{S_W}^{-1}\)</span> we then obtain <span class="math display">\[\label{eqn:Fisher&#39;s linear discriminant}
\vec{w} \propto \vec{S_W}^{-1}(\vec{m_2}-\vec{m_1})\]</span> Note that if the within-class covariance is isotropic,so that <span class="math inline">\(\vec{S_W}\)</span> is proportional to the unit matrix(<span class="math inline">\(\vec{S_W} \propto \vec{I}\)</span>),we find that <span class="math inline">\(\vec{w}\)</span> is proportional to the difference vector of the class means.</p>
<p>The result [eqn:Fisher’s linear discriminant] is known as <span class="math inline">\(Fisher&#39;s linear discriminant\)</span>,although strictly it is not a discriminant but rather a specific choice of direction for projection of the data down to one dimension.However,the projected data can subsequently be used to construct a discriminant,by choosing a threshold <span class="math inline">\(y_0\)</span> so that we classify a new point as belonging to <span class="math inline">\(\mathcal{C}_1\)</span> if <span class="math inline">\(y(\vec{x}) \geq y_0\)</span> and can classify it as belonging to <span class="math inline">\(\mathcal{C}_2\)</span> otherwise.</p>
<h3 id="extensions-to-higher-dimensions-and-multiple-classes">Extensions to higher dimensions and multiple classes</h3>
<p>We can extend the above idea to multiple classes,and to higher dimensional subspaces,by finding a projection <span class="math inline">\(matrix \vec{W}\)</span> which maps from <span class="math inline">\(D\)</span> to <span class="math inline">\(L\)</span> so as to maximize <span class="math display">\[J(\vec{W}) = \dfrac{|\vec{W}\vec{\Sigma_B}\vec{W}^T|}{|\vec{W}\Sigma_W\vec{W}^T|}\]</span> where <span class="math display">\[\begin{aligned}
\Sigma_B \triangleq \sum_{c}{\dfrac{N_c}{N}(\vec{m_c}-\vec{m})(\vec{m_c}-\vec{m})^T} \\
\Sigma_W \triangleq \sum_{c}\dfrac{N_c}{N}\Sigma_c \\
\Sigma_c \triangleq \sum_{i:y_i=c}(\vec{x_i}-\vec{m_c})(\vec{x_i}-\vec{m_c})^T\end{aligned}\]</span> The solution can be shown to be <span class="math display">\[\vec{W} = \Sigma_W^{-\frac{1}{2}}\vec{U}\]</span> where <span class="math inline">\(\vec{U}\)</span> are the <span class="math inline">\(\vec{L}\)</span> leading eigenvectors of <span class="math inline">\(\Sigma_W^{-\frac{1}{2}}\Sigma_B\Sigma_W^{-1\frac{1}{2}}\)</span>,assuming <span class="math inline">\(\Sigma_W\)</span> is non-singular.(If it is singular,we can first perform PCA on all the data).</p>
<h3 id="probabilistic-interpretation-of-flda">Probabilistic interpretation of FLDA *</h3>
<h3 id="relation-to-least-squares">Relation to least squares</h3>
<h3 id="fishers-discriminant-for-multiple-classes">Fisher’s discriminant for multiple classes</h3>
<h3 id="the-perceptron-algorithm">The perceptron algorithm</h3>
<p>Another example of a linear discriminant model is the perceptron of Rosenblatt(1962),which corresponds to a two-class transformation to give a feature vector <span class="math inline">\(\phi(\vec{x})\)</span>,and this is then used to construct a generalized linear model of the form <span class="math display">\[y(\vec{x}) = f(\vec{w}^T\vec{\phi}(\vec{x}))\]</span> where the nonlinear activation function <span class="math inline">\(f(\cdot)\)</span> is given by a step function of the form <span class="math display">\[f(a) = \begin{cases}
+1,a \geq 0 \\
-1,a \leq 0
\end{cases}\]</span></p>
<h4 id="error-function">error function</h4>
<p>A natural choice of error function would be the total number of misclassified patterns,which does not lead to a simple learning algorithm because the error is a piecewise constant function of <span class="math inline">\(\vec{w}\)</span>,with discontinuities wherever a change in <span class="math inline">\(\vec{w}\)</span> causes the decision boundary to move across one of the data points.Methods based on gradient can’t be applied.An alternative error function is known as the <strong>perceptron criterion</strong>,given by <span class="math display">\[E_P(\vec{w}) = -\sum_{n\in \mathcal{M}}{\vec{w}^T\vec{\phi_n}(\vec{x})t_n}\]</span> where we use <span class="math inline">\(t\in \{-1,+1\}\)</span> coding scheme, <span class="math inline">\(\mathcal{M}\)</span> denotes the set of all misclassified patterns.The perceptron criterion associates zero error with any pattern that is correctly classified,whereas for a misclassified pattern <span class="math inline">\(\vec{x}\)</span> it tries to minimize the quantity <span class="math inline">\(-\vec{w}^T\vec{\phi_n}t_n\)</span>.The perceptron learning rule is not guaranteed to reduce the total error function at each stage.</p>
<p>However,the <strong>perceptron convergence theorem</strong> states that if there exists an exact solution(linearly separable),then the perceptron learning algorithm is guaranteed to find an exact solution if a finite number of steps.</p>
<p>Aside from difficulties with the learning algorithm,the perceptron does not provide probabilistic outputs,nor does it generalize readily to <span class="math inline">\(K&gt;2\)</span> classes.The most important limitation,however,arises from the fact that it is based on linear combinations of fixed basis functions.</p>
<h4 id="optimization-1">optimization</h4>
<p>We now apply the stochastic gradient descent algorithm to this error function.The change in the weight vector <span class="math inline">\(\vec{w}\)</span> is then given by <span class="math display">\[\vec{w}^{\tau+1} = \vec{w}^{\tau} - \eta\nabla E_P(\vec{w}) = \vec{w}^{\tau} + \eta\phi_n t_n\]</span> where <span class="math inline">\(\eta\)</span> is the learning rate parameter and <span class="math inline">\(\tau\)</span> is an integer that indexes the steps of the algorithm.Because the perceptron function <span class="math inline">\(y(\vec{x},\vec{w})\)</span> is unchanged if we multiply <span class="math inline">\(\vec{w}\)</span> by a constant,so we can set the learning rate <span class="math inline">\(\eta\)</span> equal to 1 without of generality.</p>
<h2 id="probabilistic-generative-models">Probabilistic Generative Models</h2>
<p>We turn next to a probabilistic view of classification and show how models with linear decision boundaries arise from simple assumptions about the distribution of the data,adopting a generative approach in which we model the class-conditional densities <span class="math inline">\(p(\vec{x}|\mathcal{C}_k)\)</span>,as well as the class priors <span class="math inline">\(p(\mathcal{c}_k)\)</span>,and then use these to compute posterior probabilities <span class="math inline">\(p(\mathcal{C}_k|\vec{x})\)</span> through Bayes’ theorem.</p>
<h3 id="two-classes-1">Two classes</h3>
<p>Consider first of all the case two classes.The posterior probability for class <span class="math inline">\(\mathcal{C}_1\)</span> can be written as <span class="math display">\[\begin{aligned}
p(\mathcal{C}_1|\vec{x}) &amp;= \dfrac{p(\vec{x}|\mathcal{C}_1)p(\mathcal{C}_1)}{p(\vec{x}|\mathcal{C}_1)p(\mathcal{C}_1)+p(\vec{x}|\mathcal{C}_2)p(\mathcal{C}_2)} \\
&amp;= \dfrac{1}{1+\exp(-a)} = \sigma(a)\end{aligned}\]</span> where we have defined <span class="math display">\[a = \ln \dfrac{p(\vec{x}|\mathcal{C}_1)p(\mathcal{C}_1)}{p(\vec{x}|\mathcal{C}_2)p(\mathcal{C}_2)}\]</span> and <span class="math inline">\(\sigma(a)\)</span> is the <strong>logistic sigmoid</strong> function defined by <span class="math display">\[\sigma(a) = \dfrac{1}{1+\exp(-a)}\]</span> The term ’sigmoid’ means S-shaped,sometimes called a ’squashing function’ because it maps the whole real axis into a finite interval.It satisfies symmetry property <span class="math display">\[\sigma(-a) = 1 - \sigma(a)\]</span> The inverse of the logistic sigmoid is given by <span class="math display">\[a = \ln(\dfrac{\sigma}{1-\sigma})\]</span> and is known as the <strong>logit</strong> function.It represents the log of the ratio of probabilities <span class="math inline">\(ln[p(\mathcal{C}_1|\vec{x})/p(\mathcal{C}_2|\vec{x})]\)</span> for the two classes,also known as the <strong>log odds</strong>.</p>
<h3 id="multiple-classes-1">Multiple classes</h3>
<p>For the case of <span class="math inline">\(K&gt;2\)</span> classes,we have posterior <span class="math display">\[\begin{aligned}
p(\mathcal{C}_k|\vec{x}) 
&amp;=\dfrac{p(\vec{x}|\mathcal{C}_k)p(\mathcal{C}_k)}{\sum_{j}{p(\vec{x}|\mathcal{C}_j)p(\mathcal{C}_j)}} \\
&amp;=\dfrac{\exp(a_k)}{\sum_j\exp(a_j)}\end{aligned}\]</span> which is known as the <strong>normalized exponential</strong> and can be regarded as a multiclass generalization of the logistic sigmoid.Here the quantities <span class="math inline">\(a_k\)</span> are defined by <span class="math display">\[a_k=\ln p(\vec{x}|\mathcal{C}_k)p(\mathcal{C}_k)\]</span> The normalized function is also known as the <strong>softmax function</strong>,as it represents a smoothed version of the ’max’ function because,if <span class="math inline">\(a_k \gg a_j\)</span> for all <span class="math inline">\(j\neq k\)</span>,then <span class="math inline">\(p(\mathcal{C}_k|\vec{x}) \simeq 1\)</span> and,<span class="math inline">\(p(\mathcal{C}_j|\vec{x}) \simeq 0\)</span>.</p>
<p>The following investigate the consequences of choosing specific forms for the class-conditional densities,continuous and discrete inputs.</p>
<h3 id="continuous-inputs">Continuous inputs</h3>
<p>Assume that the class-conditional densities are <strong>Gaussian</strong> sharing the <strong>same covariance matrix</strong> and then explore the resulting form for the posterior probabilities.Thus the density(pdf) for class <span class="math inline">\(\mathcal{C}_k\)</span> is given by <span class="math display">\[p(\vec{x}|\mathcal{C}_k) = \dfrac{1}{(2\pi)^{D/2}}\dfrac{1}{|\vec{\Sigma}|^{1/2}}
\exp\{-\dfrac{1}{2}(\vec{x}-\vec{\mu}_k)^T\vec{\Sigma}^{-1}(\vec{x}-\vec{\mu}_k)  \}\]</span> In the case of two classes,we have <span class="math display">\[\begin{aligned}
a(\vec{x}) &amp;= \log\dfrac{p(\vec{x}|\mathcal{C}_1)p(\mathcal{C}_1)}
{p(\vec{x}|\mathcal{C}_2)p(\mathcal{C}_2)} \\
&amp;=-\dfrac{1}{2}(\vec{x}-\vec{\mu}_1)^T\vec{\Sigma}^{-1}(\vec{x}-\vec{\mu}_1) +
\dfrac{1}{2}(\vec{x}-\vec{\mu}_2)^T\vec{\Sigma}^{-1}(\vec{x}-\vec{\mu}_2) + \log\dfrac{p(\mathcal{C}_1)}{p(\mathcal{C}_2)} \\
&amp;=(\vec{\mu_1}-\vec{\mu_2})^T\vec{\Sigma}^{-1}\vec{x}-
\dfrac{1}{2}\vec{\mu_1}^T\vec{\Sigma}^{-1}\vec{\mu_1} +
\dfrac{1}{2}\vec{\mu_2}^T\vec{\Sigma}^{-1}\vec{\mu_2} + \log\dfrac{p(\mathcal{C}_1)}{\mathcal{C}_2} \\
&amp;=\vec{w}^T\vec{x}+w_0\end{aligned}\]</span> where <span class="math display">\[\begin{aligned}
\vec{w} &amp;= \vec{\Sigma}^{-1}(\vec{\mu_1}-\vec{\mu_2}) \\
w_0 &amp;=  -\dfrac{1}{2}\vec{\mu_1}^T\vec{\Sigma}^{-1}\vec{\mu_1} +
\dfrac{1}{2}\vec{\mu_2}^T\vec{\Sigma}^{-1}\vec{\mu_2} + \log\dfrac{p(\mathcal{C}_1)}{\mathcal{C}_2}\end{aligned}\]</span> We see that the quadratic terms in <span class="math inline">\(\vec{x}\)</span> from the exponents of the Gaussian densities have cancelled (due to the common covariance matrices) leading to a linear function of <span class="math inline">\(\vec{x}\)</span> in the argument of logistic sigmoid.The prior <span class="math inline">\(p(\mathcal{C}_k)\)</span> enter only through the bias parameter <span class="math inline">\(w_0\)</span> so that it have effect of the parallel contours of constant posterior probability.</p>
<p>For the general case of <span class="math inline">\(K\)</span> cases we have <span class="math display">\[\begin{aligned}
a_k(\vec{x}) &amp;= \log p(\vec{x}|\mathcal{C}_k)p(\mathcal{C}_k)  \\
&amp;=\vec{\mu_k}^T\vec{\Sigma}^{-1}\vec{x} - \dfrac{1}{2}{\vec{\mu_k}}^T\vec{\Sigma}^{-1}\vec{\mu_k} + \vec{x}^T\vec{\Sigma}^{-1}\vec{x}+
 \log p(\mathcal{C}_k) + const\end{aligned}\]</span> Notice that <span class="math inline">\(\vec{x}\vec{\Sigma}^{-1}\vec{x}\)</span> is cancelled in the exponent of the softmax function.Therefore we can write <span class="math display">\[a_k(\vec{x}) = \vec{w_k}^T\vec{x}+w_{k0}\]</span> where <span class="math display">\[\begin{aligned}
\vec{w_k} &amp;= \vec{\Sigma}^{-T}\vec{\mu_k} \\
w_{k0} &amp;= -\dfrac{1}{2}\vec{\mu_k}^T\vec{\Sigma}^{-1}\vec{\mu_k} + \ln p(\mathcal{C}_k)\end{aligned}\]</span> We see that the <span class="math inline">\(a_k(\vec{x})\)</span> are again linear functions of <span class="math inline">\(\vec{x}\)</span> due to the shared covariances,otherwise we obtain quadratic functions of <span class="math inline">\(\vec{x}\)</span>,giving rise to a <strong>quadratic discriminant</strong>.</p>
<h3 id="maximum-likelihood-solution">Maximum likelihood solution</h3>
<p>Having specified a parametric functional form for the class-conditional densities <span class="math inline">\(p(\vec{x}|\mathcal{C}_k)\)</span>,we can then determine the values of the parameters,together with the prior class probabilities <span class="math inline">\(p(\mathcal{C}_k)\)</span>,using <strong>maximum likelihood</strong>.</p>
<p>Consider first the case of two classes,each having a Gaussian class-conditional density with a shared covariance matrix,and suppose we have a data set <span class="math inline">\(\{\vec{x_n},\vec{t_n}\}\)</span> where <span class="math inline">\(n=1,...N\)</span>.Here <span class="math inline">\(t_n=1\)</span> denotes class <span class="math inline">\(\mathcal{C}_1\)</span> and <span class="math inline">\(0\)</span> denotes <span class="math inline">\(\mathcal{C}_2\)</span>.Denote the prior class probability <span class="math inline">\(p(\mathcal{C}_1) = \pi\)</span> so that <span class="math inline">\(p(\mathcal{C}_2) =  1- \pi\)</span>.For a data point <span class="math inline">\(\vec{x_n}\)</span> from class <span class="math inline">\(\mathcal{C}_1\)</span>,we have <span class="math inline">\(t_n=1\)</span> and hence <span class="math display">\[p(\vec{x_n},\mathcal{C}_1) = p(\mathcal{C}_1)p(\vec{x}|\mathcal{C}_1) = 
\pi \mathcal{N}(\vec{x_n}|\vec{\mu_1},\vec{\Sigma})\]</span> For class <span class="math inline">\(\mathcal{C}_2\)</span> ,and hence <span class="math display">\[p(\vec{x_n},\mathcal{C}_2) = p(\mathcal{C}_1)p(\vec{x}|\mathcal{C}_2) = 
\pi \mathcal{N}(\vec{x_n}|\vec{\mu_2},\vec{\Sigma})\]</span> Thus the likelihood is given by <span class="math display">\[p(\vec{t}|\pi,\vec{\mu_1},\vec{\mu_2}) = \prod_{n=1}^{N}
[\pi \mathcal{N}(\vec{x_n}|\vec{\mu_1},\vec{\Sigma})]^{t_n}
[(1-\pi)\mathcal{N}(\vec{x_n}|\vec{\mu_2},\vec{\Sigma})]^{1-t_n}\]</span> where <span class="math inline">\(\vec{t} = (t_1,...,t_N)^T\)</span>. Maximize the log likelihood <span class="math display">\[\log p(\vec{t}|\pi,\vec{\mu_1},\vec{\mu_2}) = 
\sum_{n=1}^{N}\{t_n\log \pi + t_n\log \mathcal{N(\vec{x_n}|\vec{\mu_1},\vec{\Sigma})}+
(1-t_n)\log(1-\pi) + (1-t_n)\log \mathcal{N}(\vec{x_n}|\vec{\mu_2},\vec{\Sigma})  \}\]</span> The terms that depend on <span class="math inline">\(\pi\)</span> are <span class="math display">\[\sum_{n=1}^{N}\{t_n\log\pi + (1-t_n)\ln(1-\pi)  \}\]</span> Setting the derivative with respect to <span class="math inline">\(\pi\)</span> equal to zero and rearranging,we obtain <span class="math display">\[\begin{aligned}
&amp;\sum_{n=1}^{N}\{t_n\dfrac{1}{\pi} +(t_n-1)\dfrac{1}{1-\pi}  \} = 0 \\
\Rightarrow &amp; \pi\sum_{n=1}^{N}(t_n-1) -\pi\sum_{n=1}^{N}t_n + \sum_{n=1}^{N}t_n = 0 \\
\Rightarrow &amp; \pi = \dfrac{1}{N}\sum_{n=1}^{N}t_n = \dfrac{N_1}{N}=\dfrac{N_1}{N_1+N_2}\end{aligned}\]</span> where <span class="math inline">\(N_k\)</span> denotes the total number of data points in class <span class="math inline">\(\mathcal{C}_k\)</span>.Thus the maximum likelihood estimate for <span class="math inline">\(pi\)</span> is simply the fraction of points in class as expected,which can be easily generalized to the multiclass case where ... .</p>
<p>Now consider the maximization with respect to <span class="math inline">\(\vec{\mu_1}\)</span>.The log likelihood function those terms that depend on <span class="math inline">\(\vec{\mu_1}\)</span> <span class="math display">\[\sum_{n=1}^{N}t_n\ln\mathcal{N}(\vec{x_n}|\vec{\mu_1},\Sigma) = 
-\dfrac{1}{2}\sum_{n=1}^{N}t_n(\vec{x_n} - \vec{\mu_1})^T\vec{\Sigma}^{-1}(\vec{x_n}-\vec{\mu_1})+ const\]</span> Setting the derivative with respect to <span class="math inline">\(\vec{\mu_1}\)</span> to zero and arranging ,we obtain <span class="math display">\[\vec{\mu_1} = \dfrac{1}{N_1}t_n\vec{x_n}\]</span> which is simply the mean of all the input vectors <span class="math inline">\(\vec{x_n}\)</span> assigned to corresponding class. Similarly, <span class="math display">\[\vec{\mu_2} = \dfrac{1}{N_2}t_n\vec{x_n}\]</span> Finally,consider the maximum likelihood solution for the shared covariance matrix <span class="math inline">\(\Sigma\)</span>.We have <span class="math display">\[\begin{aligned}
&amp;-\dfrac{1}{2}\sum_{n=1}^{N}t_n\ln|\Sigma| - 
\dfrac{1}{2}\sum_{n=1}^{N}t_n(\vec{x_n} - \vec{\mu_1})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu_1}) \\
&amp;-\dfrac{1}{2}\sum_{n=1}^{N}(1-t_n)\ln|\Sigma| - \dfrac{1}{2}\sum_{n=1}^{N}(1-t_n)(\vec{x_n}-\vec{\mu_2})^T\Sigma^{-1}(\vec{x_n}-\vec{\mu_2})\\
&amp;= -\dfrac{N}{2}\ln|\Sigma| -\dfrac{N}{2}Tr\{\Sigma^{-1}\vec{S}\} \end{aligned}\]</span> where we have defined <span class="math display">\[\begin{aligned}
\vec{S} &amp;= \dfrac{N_1}{N}\vec{S_1} + \dfrac{N_2}{N}\vec{S_2} \\
\vec{S_1}&amp;= \dfrac{1}{N_1}\sum_{n\in \mathcal{C}_1}{(\vec{x_n}-\vec{\mu_1})(\vec{x_n}-\vec{\mu_1})} \\
\vec{S_2}&amp;= \dfrac{1}{N_2}\sum_{n\in \mathcal{C}_2}{(\vec{x_n}-\vec{\mu_2})(\vec{x_n}-\vec{\mu_2})} \end{aligned}\]</span> Using the standard result for the maximum likelihood solution for a Gaussian distribution,we see that <span class="math display">\[\vec{\Sigma} = \vec{S}\]</span> which represents a weighted average of the covariance matrices associated with each of the two classes separately.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>This result is easily extended to the <span class="math inline">\(K\)</span> class problem.Note that the approach of fitting Gaussian distributions to the classes is not robust to outliers,because the maximum likelihood estimation of a Gaussian is not robust.</p>
<h3 id="discrete-features">Discrete features</h3>
<p>Assume binary feature value <span class="math inline">\(x_i\in \{0,1\}\)</span> is Bernoulli distributed,thus we have class-conditional distributions of the form <span class="math display">\[p(\vec{x}|\mathcal{C}_k) = \prod_{i=1}^{D}\mu_{ki}^{x_i}(1-\mu_{ki})^{1-x_i}\]</span> which contains <span class="math inline">\(D\)</span> independent parameters for each class,giving <span class="math display">\[a_k(\vec{x}) = \sum_{i=1}^{D}\{x_i\ln\mu_{ki}+(1-x_i)\ln(1-\mu_ki)\} + \ln p(\mathcal{C}_k)\]</span> which again are linear functions of the input values <span class="math inline">\(x_i\)</span>.Analogous results are obtained for discrete variables each of which can take <span class="math inline">\(M&gt;2\)</span> states.</p>
<h3 id="exponential-family">Exponential family</h3>
<p>As we have see so far,for both Gaussian distributed and discrete inputs,the posterior class probabilities are given by generalized linear models with logistic sigmoid(<span class="math inline">\(K=2\)</span> classes) or softmax(<span class="math inline">\(K\gg 2\)</span> classes) activation functions.These are particular cases of a more general result obtained by assuming that the class-conditional densities p(x|Ck) are members of the exponential family of distributions. Using the form [sec:exponential-family] for members of the exponential family, we see that the distribution of x can be written in the form <span class="math display">\[p(\vec{x}|\vec{\lambda_k}) = h(\vec{x})g(\vec{\lambda}_k)
\exp\{\vec{\lambda}_k^T\vec{u}(\vec{x}) \}\]</span> We restrict attention to the subclass for which <span class="math inline">\(\vec{u}(\vec{x})  = \vec{x}\)</span>.Making use of [eqn:density scale parameter] to introduce a scaling parameter <span class="math inline">\(s\)</span>,then <span class="math display">\[\label{eqn:restricted exponential family}
p(\vec{x}|\vec{\lambda_k},s) = \dfrac{1}{s}h(\vec{x}/s)g(\vec{\lambda}_k)
\exp\{\dfrac{1}{s}\vec{\lambda}_k^T\vec{u}(\vec{x}) \}\]</span> Note that each class have its own parameter vector <span class="math inline">\(\vec{\lambda}_k\)</span> but share the same scale parameter <span class="math inline">\(s\)</span>.</p>
<p>For the two-class problem,the posterior is given by a logistic sigmoid acting on a linear function <span class="math display">\[a(\vec{x}) = (\vec{\lambda}_1-\vec{\lambda}_2)^T\vec{x} + \ln g(\vec{\lambda}_1) - \ln g(\vec{\lambda}_2) +\ln p(\mathcal{C}_1)-\ln p(\mathcal{C}_2)\]</span> Similarly,for the <span class="math inline">\(K\)</span>-class problem, <span class="math display">\[a_k(\vec{x}) = \vec{\lambda}_k^T\vec{x}+\ln g(\vec{\lambda}_k)+\ln p(\mathcal{C}_k)\]</span> and so again is a linear function of <span class="math inline">\(\vec{x}\)</span>.</p>
<h2 id="probabilistic-discriminative-models">Probabilistic Discriminative Models</h2>
<p>We have seen that the posterior probability for the two-class classification and multiclass case can be written as a logistic and softmax function respectively for a wide choice of class-conditional distributions <span class="math inline">\(p(\vec{x}|\mathcal{C}_k)\)</span>.For a specific class-conditional densities <span class="math inline">\(p(\vec{x}|\mathcal{C}_k)\)</span>,we use maximum likelihood to determine the parameters of the densities as well as the class priors <span class="math inline">\(p(\mathcal{C}_k)\)</span> and use Bayes’ theorem to find the posterior class probabilities.However,an alternative approach is to use the functional form of the generalized linear model explicitly and to determine its parameters directly by using maximum likelihood,such as <strong>iterative reweighted least squares</strong> or IRLS.</p>
<p>The indirect approach to finding the parameters of a generalized linear model by fitting class-conditional densities and class priors separately and then applying Bayes’ theorem,represents an example of <strong>gernerative modelling</strong>，because we could take such a model and generate synthetic data by drawing values of <span class="math inline">\(\vec{x}\)</span> from the marginal distribution <span class="math inline">\(p(\vec{x})\)</span>.In the direct approach,we maximize a likelihood function defined through the conditional distribution <span class="math inline">\(p(\mathcal{C}_k|\vec{x})\)</span>,which represents a form of <strong>discriminative</strong> training.</p>
<h3 id="fixed-basis-functions">Fixed basis functions</h3>
<p>So far,we have considered classification models that work directly with the original input vector <span class="math inline">\(\vec{x}\)</span>.However,all of the algorithms can equally applicable if we first make a fixed nonlinear transformation of the inputs using a vector of basis functions <span class="math inline">\(\phi(\vec{x})\)</span>.The resulting decision boundaries will be linear in the feature space <span class="math inline">\(\phi\)</span>,corresponding to nonlinear decision boundaries in the original <span class="math inline">\(\vec{x}\)</span> space.One of the basis function is typically set to a constant,say <span class="math inline">\(\phi_0(\vec{x})=1\)</span>,so that the corresponding parameter <span class="math inline">\(w_0\)</span> plays the role of a bias.</p>
<p>Note that nonlinear transformations cannot remove class overlap between the class-conditional densities <span class="math inline">\(p(\vec{x}|\mathcal{C}_k)\)</span>.</p>
<h3 id="logistic-regression">Logistic regression</h3>
<h4 id="representation-1">representation</h4>
<p>We begin with two-class classification.The posterior probability of class <span class="math inline">\(\mathcal{C}_1\)</span> can be written as a logistic sigmoid acting on a linear function of the feature vector <span class="math inline">\(\phi\)</span> so that <span class="math display">\[p(\mathcal{C}_1|\phi) = y(\phi) = \sigma(\vec{w}^T\phi)\]</span> which has a linear dependence on the number of parameters.Logistic regression model can also be written as <span class="math display">\[p(y|\vec{x},\vec{w})=\mathrm{Ber}(y|\mathrm{sigm}(\vec{w}^T\vec{\phi}))\]</span> where <span class="math inline">\(\vec{w}\)</span> and <span class="math inline">\(\vec{\phi}\)</span> are extended vectors, i.e., <span class="math inline">\(\vec{w}=(b, w_1, w_2,\cdots, w_D)\)</span>, <span class="math inline">\(\vec{\phi}=(1, \phi_1, \phi_2,\cdots, \phi_D)\)</span>.</p>
<p>Note that the derivative of the logistic sigmoid function is <span class="math display">\[\dfrac{d\sigma}{da} = \sigma(1-\sigma)\]</span></p>
<h4 id="evaluation-1">evaluation</h4>
<p>For a data set <span class="math inline">\(\{\phi_n,t_n \}\)</span>,where <span class="math inline">\(t_n \in \{0,1\}\)</span> and <span class="math inline">\(\phi_n = \phi(\vec{x_n})\)</span>,with <span class="math inline">\(n = 1,...,N\)</span>,the likelihood function can be written <span class="math display">\[p(\vec{t}|\vec{w}) = \prod_{n=1}^{N}y_n^{t_n}\{1-y_n \}^{1-t_n}\]</span> where <span class="math inline">\(\vec{t}=(t_1,...,t_N)^T\)</span> and <span class="math inline">\(y_n = p(\mathcal{C}_1|\phi_n)\)</span>.The negative logarithm of the likelihood,which gives the <strong>cross-entropy</strong> error function is in the form <span class="math display">\[E(\vec{w})=-\ln p(\vec{t}|\vec{w})=-\sum_{n=1}^{N}\{t_n\ln y_n +(1-t_n)\ln (1-y_n) \}\]</span> Taking the gradient of the error function with respect to <span class="math inline">\(\vec{w}\)</span>,we obtain <span class="math display">\[\begin{aligned}
\nabla E(\vec{w}) 
&amp;=-\sum\limits_{n=1}^{N}\{t_n\dfrac{y_n(1-y_n)}{y_n}-
(1-t_n)\dfrac{y_n(q-y_n)}{1-y_n} \}\phi_n\\
&amp;=-\sum_{n=1}^{N}\{t_n(1-y_n)-(1-t_n)y_n \}\phi_n\\
&amp;=\sum_{n=1}^{N}(y_n-t_n)\phi_n\end{aligned}\]</span> We see that the factor involving the derivative of the logistic sigmoid has cancelled.In particular,the contribution to the gradient from data point <span class="math inline">\(n\)</span> is given by the ’error’ <span class="math inline">\(y_n-t_n\)</span> between the target value and the prediction of the model,times the basis function vector <span class="math inline">\(\phi_n\)</span>,taking the same form as the gradient of the sum-of-squares error function for the linear regression model.</p>
<p>Note that maximum likelihood can exhibit severe <strong>over-fitting</strong> for data sets that are linearly separable.The singularity can be avoided by inclusion of a prior and finding a <strong>MAP(maximum a posterior)</strong> solution for <span class="math inline">\(\vec{w}\)</span>,or equivalently by adding a <strong>regularization</strong> term to the error function.</p>
<h4 id="optimization-2">optimization</h4>
<p>See the following contents.</p>
<h3 id="iterative-reweighted-least-squares">Iterative reweighted least squares</h3>
<h4 id="newton-raphson-update">Newton-Raphson update</h4>
<p>For logistic regression,there is no longer a closed-form solution,due to the nonlinearity of the logistic sigmoid function.The error function is concave,and can be minimized by an efficient iterative technique based on the <strong>Newton-Raphson</strong> iterative optimization scheme,which uses a local quadratic approximation to the log likelihood function. <span class="math display">\[\vec{w}^{(new)} = \vec{w}^{(old)}-\vec{H}^{-1}\nabla E(\vec{w})\]</span> where <span class="math inline">\(\vec{H}\)</span> is the Hessian matrix whose elements comprise the second derivatives of <span class="math inline">\(E(\vec{w})\)</span> with respect to the components of <span class="math inline">\(\vec{w}\)</span>.</p>
<p>Now apply the Newton-Raphson method ot the linear regression model with sum-of-squares error function.The gradient and Hessian of this error function are given by <span class="math display">\[\begin{aligned}
\nabla E(\vec{w}) &amp;= \sum_{n=1}^{N}(\vec{w}^T\phi_n-t_n)\phi_n = \vec{\Phi}^T\vec{\Phi}\vec{w} - \vec{\Phi}^T\vec{t} \\
\vec{H} = \nabla\nabla E(\vec{w}) &amp;= \sum_{n=1}^{N}\phi_n\phi_n^T=\vec{\phi}^T\vec{\Phi}\end{aligned}\]</span> where <span class="math inline">\(\vec{\Phi}\)</span> is the <span class="math inline">\(N\times N\)</span> design matrix,whose <span class="math inline">\(n^{th}\)</span> row is given by <span class="math inline">\(\phi_n^T\)</span>.The Newton-Raphson update then takes the form <span class="math display">\[\begin{aligned}
\vec{w}^{(new)} &amp;= \vec{w}^{(old)} -(\vec{\Phi}^T\vec{\Phi})^{-1}\{\vec{\Phi}^T\vec{\Phi}\vec{w}^{(old)} -\vec{\Phi}^T\vec{t} \} \\
&amp;=(\vec{\Phi}^T\vec{\Phi})^{-1}\vec{\Phi}^T\vec{t}\end{aligned}\]</span> which we recognize as the standard least-squares solution.</p>
<p>Now apply the Newton-Raphson update to the cross-entropy error function for logistic regression model.Gradient and Hessian of this error function are given by <span class="math display">\[\begin{aligned}
\nabla E(\vec{w})&amp;=\sum_{n=1}^{N}(y_n-t_n)\phi_n
=\vec{\Phi}^T(\vec{y}-\vec{t}) \\
\vec{H} &amp;= \nabla\nabla E(\vec{w})= \sum_{n=1}^{N}y_n(1-y_n)\phi_n\phi_n^T=\vec{\Phi}^T\vec{R}\vec{\Phi}\end{aligned}\]</span> where we have introduced the <span class="math inline">\(N\times N\)</span> diagonal matrix <span class="math inline">\(\vec{R}\)</span> with elements <span class="math display">\[R_{nn}=y_n(1-y_n)\]</span> We see that the Hessian depends on <span class="math inline">\(\vec{w}\)</span> and is positive definite.</p>
<p>The Newton-Raphson update formula for the logistic regression model then becomes <span class="math display">\[\begin{aligned}
\vec{w}^{(new)} &amp;= \vec{w}^{(old)} -(\vec{\Phi}^T\vec{R}\vec{\Phi})^{-1}\vec{\Phi}^T(\vec{y}-\vec{t}) \\
&amp;=(\vec{\Phi}^T\vec{R}\vec{\Phi})^{-1}\{\vec{\Phi}^T\vec{R}\vec{\Phi}\vec{w}^{(old)} -\vec{\Phi}^T(\vec{y}-\vec{t}) \} \\
&amp;=(\vec{\Phi}^T\vec{R}\vec{\Phi})^{-1}\vec{\Phi}^T\vec{R}\vec{z}\end{aligned}\]</span> where <span class="math inline">\(\vec{z}\)</span> is an <span class="math inline">\(N\)</span>-dimensional vector with elements <span class="math display">\[\vec{z} = \vec{\Phi}\vec{w}^{(old)}-\vec{R}^{-1}(\vec{y}-\vec{t})\]</span> We see that the update formula takes the form of a set of normal equations for a weighted least-squares problem.Because the weighting matrix <span class="math inline">\(\vec{R}\)</span> depends on the parameter vector <span class="math inline">\(\vec{w}\)</span>,we must apply the normal equations iteratively,each time using the new weight vector <span class="math inline">\(\vec{w}\)</span> to compute a revised weighing matrix <span class="math inline">\(\vec{R}\)</span>.For this reason,the algorithm is known as <strong>iterative reweighted least squares</strong>,or IRLS.The elements of the diagonal weighing matrix <span class="math inline">\(\vec{R}\)</span> can be interpreted as variances because the mean and variance of <span class="math inline">\(t\)</span> in the logistic regression model are given by <span class="math display">\[\begin{aligned}
\mathbb{E}[t] &amp;=\sigma(\vec{x}) = y\\
var[t]&amp;=\mathbb{E}[t^2] -\mathbb{E}[t]^2 = \sigma(\vec{x})-\sigma(\vec{x})^2 = y(1-y)\end{aligned}\]</span> where we have used the property <span class="math inline">\(t^2=t\)</span> for <span class="math inline">\(t\in \{0,1\}\)</span>.</p>
<h4 id="linearization">Linearization</h4>
<p>In fact,we can interpret IRLS as the solution to a linearized problem in the space of the variable <span class="math inline">\(a=\vec{w}^T\phi\)</span>.Apply Taylor expansion and then we obtain <span class="math display">\[\begin{aligned}
a_n(\vec{w}) &amp;\simeq a_n(\vec{w}^{(old)})+\dfrac{da_n}{dy_n}\bigg|_{w^{(old)}}(t_n-y_n) \\
&amp;=\vec{\phi}_n^T\vec{w}^{(old)}-\dfrac{(y_n-t_n)}{y_n(1-y_n)} =z_n\end{aligned}\]</span></p>
<h3 id="multiclass-logistic-regression">Multiclass logistic regression</h3>
<p>In our discussion of generative models for multiclass classification,the posterior probabilities are given by a softmax transformation of linear functions of the feature variables,so that <span class="math display">\[\begin{aligned}
p(\mathcal{C}_k|\phi) = y_k(\phi) &amp;= \dfrac{\exp(a_k)}{\sum_j\exp(a_j)}\\
&amp;=\dfrac{\exp(a_k)}{sum} \\
%&amp;=\dfrac{1}{1+\sum_{j\neq k}\exp(a_j-a_k)}\end{aligned}\]</span></p>
<p>where <span class="math inline">\(sum\)</span> denotes <span class="math inline">\(\sum_j\exp(a_j)\)</span> the ’activations’ <span class="math inline">\(a_k\)</span> are given by <span class="math display">\[a_k = \vec{w}_k^T\phi\]</span></p>
<p>Here we consider the use of maximum likelihood to determine the parameters <span class="math inline">\(\{\vec{w}_k\}\)</span> of this model directly.The derivatives of <span class="math inline">\(y_k\)</span> with respect to all of the activations <span class="math inline">\(a_j\)</span> are given by <span class="math display">\[\begin{aligned}
\dfrac{\partial y_k}{\partial a_j} 
&amp;=\dfrac{e^{a_k}\vec{I}_{kj}sum-e^{a_k}e^{a_j}}{sum^2} \\
%&amp;=\dfrac{\partial\dfrac{1}{1+\sum_{i\neq k}\exp(a_i-a_k)}}{\partial a_j}\\
%&amp;=-\dfrac{e^{a_i-a_k}}{(1+\sum_{i\neq k}e^{a_i-a_k})^2}\\  
&amp;=y_k(I_{kj}-y_j)\end{aligned}\]</span> where <span class="math inline">\(\vec{I}_{kj}\)</span> are the elements of the identity matrix.</p>
<p>Next we write down the likelihood function,using the <span class="math inline">\(1-of-K\)</span> coding scheme. <span class="math display">\[p(\vec{T}|\vec{w}_1,...,\vec{w}_K)=
\prod_{n=1}^{N}\prod_{k=1}^{K}p(\mathcal{C}_k|\phi_n)^{t_{nk}}
=\prod_{n=1}^{N}\prod_{k=1}^{K}y_{nk}^{t_{nk}}\]</span> where <span class="math inline">\(y_{nk}=y_k(\phi_n)\)</span>,and <span class="math inline">\(\vec{T}\)</span> is an <span class="math inline">\(N\times N\)</span> matrix of target variables with elements <span class="math inline">\(t_{nk}\)</span>.Taking the negative logarithm then gives <span class="math display">\[E(\vec{w_1},...,\vec{w_K})=-\ln p(\vec{T}|\vec{w}_1,...,\vec{w}_K)
=-\sum_{n=1}^{N}\sum_{k=1}^{K}t_{nk}\ln y_{nk}\]</span> which is known as the <span class="math inline">\(cross-entropy\)</span> error function for the multiclass classification problem.</p>
<p>Take the gradient of the error function,making use of the derivatives of the softmax function,we obtain <span class="math display">\[\nabla_{w_j}E(\vec{w_1},...,\vec{w_K}) =
\sum_{n=1}^{N}(y_{nj}-t_{nj})\phi_n\]</span></p>
<p>To find a batch algorithm,we evaluate the Hessian matrix <span class="math display">\[\nabla_{w_k}\nabla_{w_j}E(\vec{w_1},...,\vec{w_K})
=-\sum_{n=1}^{N}y_{nk}(I_{kj}-y_{nj})\phi_n\phi_n^T\]</span> The Hessian matrix is also positive definite and so the error function has a unique minimum.</p>
<h3 id="probit-regression">Probit regression</h3>
<p>A broad range of class-conditional distributions,described by the exponential family,the resulting posterior class probabilities are given by a logistic(or softmax) transformation acting on a linear function of the feature variables,but not all choices of class-conditional density give rise to such a simple form for the posterior probabilities.</p>
<p>The cumulative distribution function is given by <span class="math display">\[\Phi(a) = \int_{-\infty}^{a}\mathcal{N}(\theta|0,1)d\theta\]</span> which is known as the <strong>probit function</strong>.It has a sigmoidal shape.A evaluation of a closely related function is <span class="math display">\[erf(a) = \dfrac{2}{\sqrt{\pi}}\int_{0}^{a}\exp(-\theta^2/2)d\theta\]</span> known as the <strong>erf function</strong> or <strong>error function</strong>.The generalized linear model based on a probit function is known as <strong>probit regression</strong>.</p>
<p>One issue that occur in practical applications is that of <strong>outliers</strong>.Because probit activation function they decay like <span class="math inline">\(\exp(-x^2)\)</span>,so probit model can be significantly more sensitive to outliers.However,the effect of mislabelling is easily incoporated into a probabilistic model by introducing a probability <span class="math inline">\(\epsilon\)</span> that the target value <span class="math inline">\(t\)</span> has been flipped to the wrong value, <span class="math display">\[\begin{aligned}
p(t|\vec{x}) &amp;= (1-\epsilon)\sigma(\vec{x})+\epsilon(1-\sigma(\vec{x}))\\
&amp;=\epsilon + (1-2\epsilon)\sigma(\vec{x})\end{aligned}\]</span> where <span class="math inline">\(\sigma(\vec{x})\)</span> is the activation function with input vector <span class="math inline">\(\vec{x}\)</span>.Here <span class="math inline">\(\epsilon\)</span> may be set in advance,or it may be treated as a <strong>hyperparameter</strong> whose value is inferred from data.</p>
<h3 id="canonical-link-functions">Canonical link functions</h3>
<p>We now show that there is a general result of assuming a conditional distribution for the target variable from the exponential family,along with a corresponding choice for the activation function known as the <strong>canonical link function</strong>.</p>
<p>Making use of the restricted form of exponential family distribution [eqn:restricted exponential family] for target variable <span class="math inline">\(t\)</span> <span class="math display">\[p(t|\eta,s)=\dfrac{1}{s}h(\dfrac{t}{s})g(\eta)\exp\{\dfrac{\eta t}{s}\}\]</span> The conditional mean of <span class="math inline">\(t\)</span>,which denoted by <span class="math inline">\(y\)</span>,is given by <span class="math display">\[y \equiv \mathbb{E}[t|\eta]=-s\dfrac{d}{d\eta}\ln g(\eta)\]</span> Thus <span class="math inline">\(y\)</span> and <span class="math inline">\(\eta\)</span> must be related,and we denote this relation through <span class="math inline">\(\eta = \psi(y)\)</span>.</p>
<p>We define a <strong>generalized linear model</strong> to be one for which <span class="math inline">\(y\)</span> is a nonlinear function of a linear combination of the input(or feature) variables so that <span class="math display">\[y=f(\vec{w}^T\vec{\phi})\]</span> where <span class="math inline">\(f(\cdot)\)</span> is known as the <strong>activation function</strong>,and <span class="math inline">\(f^{-1}(\cdot)\)</span> is known as the <strong>link function</strong> in statistics.</p>
<p>The log likelihood function for this model,which,as a function of <span class="math inline">\(\eta\)</span> ,is given by <span class="math display">\[\ln p(\vec{t}|\eta,s) = \sum_{n=1}^{N}\ln p(t_n|\eta,s) = \sum_{n=1}^{N}\{\ln g(\eta_n)+\dfrac{\eta_n t_n}{s} \} + const\]</span> where we assume that all observations share a common scale parameter(which corresponds to the noise variance for a Gaussian distribution for instance) and so <span class="math inline">\(s\)</span> is independent of <span class="math inline">\(\eta\)</span>.The derivative with respect to the model parameter <span class="math inline">\(\vec{w}\)</span> is then given by <span class="math display">\[\begin{aligned}
\nabla_w\ln p(\vec{t}|\eta,s) 
&amp;=\sum_{n=1}^{N}\{\dfrac{d}{d\eta_n}\ln g(\eta_n)+\dfrac{t_n}{s} \} \dfrac{d\eta_n}{dy_n}\dfrac{dy_n}{da_n}\nabla a_n \\
&amp;= \sum_{n=1}^{N}\dfrac{1}{s}\{t_n-y_n \}\psi&#39;(y_n)f&#39;(a_n)\phi_n\end{aligned}\]</span> where <span class="math inline">\(a_n=\vec{w}^T\vec{\phi_n}\)</span>,and we have used <span class="math inline">\(y_n=f(a_n)\)</span> together.There is a considerable simplification if we choose a particular form of the link function <span class="math inline">\(f^{-1}(y)\)</span> given by <span class="math display">\[f^{-1}(y) = \psi(y)\]</span> In this case,the gradient of error function reduces to <span class="math display">\[\nabla\ln E(\vec{w}) = \dfrac{1}{s}\sum_{n=1}^{N}\{y_n-t_n\}\phi_n\]</span> For the Gaussian <span class="math inline">\(s=\beta^{-1}\)</span>,whereas for logistic model <span class="math inline">\(s=1\)</span>.</p>
<h3 id="the-laplace-approximation">The Laplace Approximation</h3>
<h3 id="model-comparison-and-bic">Model comparison and BIC</h3>
<h2 id="bayesian-logistic-regression">Bayesian Logistic Regression</h2>
<h3 id="laplace-approximation">Laplace approximation</h3>
<h3 id="predictive-distribution">Predictive distribution</h3>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>?<a href="#fnref1">↩</a></p></li>
</ol>
</div>
</body>
</html>
