<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="chap:Graphical Models">Graphical Models</h1>
<h2 id="introduction">Introduction</h2>
<h2 id="directed-graph">Directed Graph</h2>
<h2 id="undirected-graph">Undirected Graph</h2>
<h2 id="inference-in-graphical-models">Inference in Graphical Models</h2>
<h3 id="factor-graphs">Factor graphs</h3>
<p>The joint distribution over a set of variables in the form of a product of factors <span class="math display">\[\begin{aligned}
p(\vec{x}) = \prod_s f_s(\vec{x}_s)\end{aligned}\]</span> where <span class="math inline">\(\vec{x}_s\)</span> denotes a set of the variables.We shall denote individual variable by <span class="math inline">\(x_i\)</span>,which can comprise groups of variables(such as vectors and matrices).Each factor <span class="math inline">\(f_s\)</span> is a function of a corresponding set of variable <span class="math inline">\(\vec{x}_s\)</span>. Directed graphs have factors <span class="math inline">\(f_s(\vec{x}_s)\)</span> as local conditional distributions.Undirected graphsâ€™ factors are potential function over the maximal cliques.</p>
<h3 id="the-sum-product-algorithm">The Sum-product algorithm</h3>
<p><strong>sum-product</strong> algorithm solves the problem of evaluating the <strong>local marginals</strong> over nodes or subsets of nodes.And <strong>max-sum</strong> algorithm find the <strong>most probable state</strong>,evaluating the maximal joint distribution.</p>
<p>The marginal is obtained by <span class="math display">\[\begin{aligned}
p(x) = \sum_{\vec{x}\backslash x}{p(\vec{x})}\end{aligned}\]</span> where <span class="math inline">\(\backslash x\)</span> denotes the set of variables in <span class="math inline">\(\vec{x}\)</span> omitting <span class="math inline">\(x\)</span>.</p>
<p>Join distribution <span class="math display">\[\begin{aligned}
p(\vec{x}) =\prod_{s\in \text{ne}(x)}{F_s(x,\vec{X}_s)}\end{aligned}\]</span></p>
<p>Then interchanging the sums and products,we obtain <span class="math display">\[\begin{aligned}
\text{objective} &amp;= p(x)=\sum_{\vec{x}\backslash x}{p(\vec{x})} \\
&amp;= \prod_{s\in\text{ne}(x)}{\left[\sum_{X_s}F_s(x,X_s)\right]} \\
&amp;= \prod_{s\in\text{ne}(x)}\mu_{f_s\rightarrow x}(x)\end{aligned}\]</span> View <strong>messages</strong> from the factor nodes <span class="math inline">\(f_s\)</span> to the variable node <span class="math inline">\(x\)</span> as <span class="math display">\[\begin{aligned}
\mu_{f_s\rightarrow x}(x) &amp;\equiv \sum_{X_s}F_s(x,X_s) \\
F_s(x,X_s) &amp;= f_s(x,x_1,\ldots,x_M)G_1(x_1,X_{s1})\ldots G_M(x_M,X_{sM})\end{aligned}\]</span></p>
<p>Recursive inference in the sub-graph and interchanging sums and products leads to <span class="math display">\[\begin{aligned}
\mu_{f_s\rightarrow x}(x) &amp;= \sum_{x_1}\ldots\sum_{x_M} f_s(x,x_1,\ldots,x_M)\prod_{m\in \text{ne}(f_s)\backslash x} \mu_{x_m\rightarrow f_s}(x_m) \end{aligned}\]</span> where <span class="math inline">\(\text{ne}(x)\)</span> denotes the set of neighbor variables. And define <strong>messages</strong> from variable nodes to factor nodes <span class="math display">\[\begin{aligned}
\mu_{x_m\rightarrow f_s}(x_m) &amp;\equiv \sum_{X_{sm}}G_m(x_m,X_{sm})\end{aligned}\]</span></p>
<p>Again,making use of (sub)-graph factorization,we have <span class="math display">\[\begin{aligned}
\mu_{x_m\rightarrow f_s}(x_m) &amp;= \prod_{l\in \text{ne}(x_m)\backslash f_s}\left[\sum_{X_{ml}}F_l(x_m,X_{ml}) \right] \\
&amp;=\prod_{l\in \text{ne}(x_m)\backslash f_s}\mu_{f_l\rightarrow x_m}(x_m)\end{aligned}\]</span></p>
<h3 id="max-sum-algorithm">Max-sum algorithm</h3>
<p>The <strong>sum-product</strong> algorithm allows us to take a joint distribution <span class="math inline">\(p(\vec(x))\)</span> expressed as a factor graph and efficiently find marginal component variables.<strong>Max-sum</strong> find a setting of variables that has the largest probability,which is an application of <strong>dynamic programming</strong>. Maximize the joint distribution <span class="math display">\[\begin{aligned}
\vec{x}^{max} = \arg\max_{\vec{x}}p(\vec{x})\end{aligned}\]</span> Joint distribution <span class="math display">\[\begin{aligned}
p(\vec{x}) &amp;= \prod_{s\in \text{ne}(x)}F_s(x,X_s)\end{aligned}\]</span> Making use of <strong>distributive law</strong> for multiplication with max operator,similarly to add operator <span class="math display">\[\begin{aligned}
\text{objective} &amp;= \max\ln p(\vec{x}) =\max\sum\ln F_s(x,X_s) \\
&amp;=\sum\max\ln F_s(x,X_s)\end{aligned}\]</span> Making use of recursion,factorize <span class="math inline">\(F_s(x,X_s)\)</span> with sub-graph,we can obtain <span class="math display">\[\begin{aligned}
\mu_{f\rightarrow x} &amp;= \max_{x_1,\ldots,x_M}\left[\ln f(x,x_1,\ldots,x_M) + \sum_{m\in \text{ne}(f_s)\backslash x} {\mu_{x_m\rightarrow f}(x_m)} \right] \\
\mu_{x\rightarrow f}(x) &amp;= \sum_{l\in \text{ne}(x)\backslash f}{\mu_{f_l\rightarrow x}}(x).\end{aligned}\]</span> where <span class="math inline">\(\mu_{f\rightarrow x} \equiv \max\ln F_s(x,X_s)\)</span></p>
</body>
</html>
