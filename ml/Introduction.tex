\chapter{Introduction}
\label{chapter:Introduction}

\section{Types of machine learning}
\begin{equation}\nonumber
\begin{cases}
\text{Supervised Learning} \begin{cases} \text{Classification} \\ \text{Regression} \end{cases}\\
\text{Unsupervised Learning} \begin{cases} \text{Discovering clusters} \\ \text{Discovering latent factors} \\ \text{Discovering graph structure} \\ \text{Matrix completion} \end{cases}\\
\text{Reinforcement Learning}
\end{cases}
\end{equation}
In the \textbf{predictive} or \textbf{supervised learning} approach,the goal is to learn a \textbf{mapping} from \textbf{inputs} $\mathbf{x}$ to \textbf{outputs} $y$,given a labeled set of input-output paris $D=\{(\mathbf{x_i},y_i)\}_{i=1}{N}$.Here $D$ is called the \textbf{training set},and N is the number of training examples.
In the simplest setting,each training input $\mathbf{x_i}$ is a D-dimensional vector of numbers,representing,say,the height and weight of a person,which are called \textbf{features,attributes,or covariates}.

\section{Supervised learning}
  Similarly the form of the output or \textbf{response variable} can in principle be anything,but most methods assume that $y_i$ is \textbf{categorical or nominal} variable from some finite set,$y_i \in \{1,...,C\}$.When $y_i$ is categorical,the problem is known as \textbf{classification or pattern recognition},and when real-valued,known as \textbf{regression}.
\subsection{Classification}
  Here the goal is to learn a mapping from inputs $x$ to outputs $y$,where $y \in \{1,...,C\}$,with $C$ being the number of classes.If $C=2$,this is called \textbf{binary classification};if $C>2$,this is called \textbf{multiclass classification}.if the class labels are not mutually exclusive,we call it \textbf{multi-label classification},but this is best viewed as predicting multiple related binary class labels(a so-called \textbf{multiple output model}).
  One way to formalize the problem is as \textbf{function approximation}:assume $y=f(\mathbf{x})$ for some unknown function $f$,and the goal of learning is to estimate the function $f$ given a labeled training set,and then to make predictions(estimate) using $\hat{y} =\hat{f}(\mathbf{x})$.Our main goal is to make predictions on novel inputs,meaning ones that we have not seen before(\textbf{generalization}.
\subsubsection{Probabilistic predictions}
We denote the probability distribution over possible labels,given the input vector $\vec{x}$ and training set $\mathcal{D}$ by $p(y|\vec{x},\mathcal{D})$.
Given a probabilistic output,we can always compute out "best guess" as to the "true label" using
\begin{equation}
\hat{y} = \hat{f}(\mathbf{x}) = \arg\max\limits_{c=1}^{C} p(y=c|\mathbf{x},D)
\end{equation}
This corresponds to the most probable class label,and is called the \textbf{mode} of distribution $p(y|\vec{x},\mathcal{D})$;it is also known as a \textbf{MAP estimate}(MAP stands for\textbf{maximum a posteriori}).
\subsubsection{Applications}
\subsection{Regression}

\section{Unsupervised learning}
  \textbf{Descriptive or unsupervised learning} approach is sometimes called \textbf{knowledge discovery}.We will formalize out task as one of \textbf{density estimation},that is we want to build models of the form $p(\mathbf{x_i|\theta})$,instead of $p(y_i|\mathbf{x_i,\theta})$.
\subsection{Discovering clusters}
Let $z_i \in \{1,...,K\}$ represent the cluster to which data point $i$ is assigned.($z_i$ is an exmaple of \textbf{hidden or latent} variable).
\subsection{Discovering latent factors}
Although the data may appear high dimensional,there may only be a small number of degrees of variability,corresponding to \textbf{latent factors}.The most common approach to dimensionality reduction is called \textbf{principal components analysis or PCA}.
\subsection{Discovering graph structure}
\subsection{Matrix completion}
\subsubsection{Image inpainting}
\subsubsection{Collaborative filtering}
\subsubsection{Market basket analysis}

\section{Three elements of a machine learning model}

\textbf{Model = Representation + Evaluation + Optimization}\footnote{Domingos, P. A few useful things to know about machine learning. Commun. ACM. 55(10):78–87 (2012).}


\subsection{Representation}
In supervised learning, a model must be represented as a conditional probability distribution $P(y|\vec{x})$(usually we call it classifier) or a decision function $f(x)$. The set of classifiers(or decision functions) is called the hypothesis space of the model. Choosing a representation for a model is tantamount to choosing the hypothesis space that it can possibly learn. 


\subsection{Evaluation}
In the hypothesis space, an evaluation function (also called objective function or risk function) is needed to distinguish good classifiers(or decision functions) from bad ones.


\subsubsection{Loss function and risk function}
\label{sec:Loss-function-and-risk-function}

\begin{definition}
In order to measure how well a function fits the training data, a \textbf{loss function} $L:Y \times Y \rightarrow R \geq 0$ is defined. For training example $(x_i,y_i)$, the loss of predicting the value $\widehat{y}$ is $L(y_i,\widehat{y})$.
\end{definition}

The following is some common loss functions:
\begin{enumerate}
\item 0-1 loss function \\ $L(Y,f(X))=\mathbb{I}(Y,f(X))=\begin{cases} 1, & Y=f(X) \\ 0, & Y \neq f(X) \end{cases}$
\item Quadratic(squared) loss function $L(Y,f(X))=\frac{1}{2}\left(Y-f(X)\right)^2$
\item Absolute loss function $L(Y,f(X))=\abs{Y-f(X)}$
\item Exponential loss function $L(Y,f(X)=exp(-\hat{y_i}f(\mathbf{x_i}))$ 
\item Logarithmic loss function \\ $L(Y,P(Y|X))=-\log{P(Y|X)}$
\end{enumerate}

\begin{tabular}{l*{3}{c}r}
Name & Loss & Derivative & $f^*$ & Algorithm                                                                                 \\
\hline
Squared error & $\frac{1}{2}(y_i-f(\mathbf{x_i}))^2$ & $y_i - f(\mathbf{x_i})$ & $\mathbb{E}[y|\mathbf{x_i}]$ & L2Boosting \\
Absolute error & $|y_i-f(\mathbf{x_i})|$ & $sgn(y_i-f(\mathbf{x_i}))$ & $median(y|\mathbf{x_i})$ & Gradient boosting \\
Exponential loss & $exp(-\hat{y_i}f(\mathbf{x_i}))$ & $-\hat{y_i}exp(-\hat{y_i}f(\mathbf{x_i}))$ & $\frac{1}{2}log\frac{\pi_i}{1-\pi_i}$ & AdaBoost \\
Logloss & $log(1+e^{-\hat{y_i}f_i})$ & $y_i-\pi_i$ & $\frac{1}{2}log\frac{\pi_i}{1-\pi_i•}$ & LogitBoost \\
\hline
\end{tabular}

\begin{definition}
The risk of function $f$ is defined as the expected loss of $f$:
\begin{equation}\label{eqn:expected-loss}
R_{\mathrm{exp}}(f)=E\left[L\left(Y,f(X)\right)\right]=\int L\left(y,f(x)\right)P(x,y)\mathrm{d}x\mathrm{d}y
\end{equation}
which is also called expected loss or \textbf{risk function}.
\end{definition}

\begin{definition}
The risk function $R_{\mathrm{exp}}(f)$ can be estimated from the training data as
\begin{equation}
R_{\mathrm{emp}}(f)=\dfrac{1}{N}\sum\limits_{i=1}^{N} L\left(y_i,f(x_i)\right)
\end{equation}
which is also called empirical loss or \textbf{empirical risk}.
\end{definition}

You can define your own loss function, but if you're a novice, you're probably better off using one from the literature. There are conditions that loss functions should meet\footnote{\url{http://t.cn/zTrDxLO}}:
\begin{enumerate}
\item They should approximate the actual loss you're trying to minimize. As was said in the other answer, the standard loss functions for classification is zero-one-loss (misclassification rate) and the ones used for training classifiers are approximations of that loss.
\item The loss function should work with your intended optimization algorithm. That's why zero-one-loss is not used directly: it doesn't work with gradient-based optimization methods since it doesn't have a well-defined gradient (or even a subgradient, like the hinge loss for SVMs has).

The main algorithm that optimizes the zero-one-loss directly is the old perceptron algorithm(chapter \S \ref{chap:Perceptron}).
\end{enumerate}


\subsubsection{ERM and SRM}
\begin{definition}
ERM(Empirical risk minimization)
\begin{equation}
\min\limits _{f \in \mathcal{F}} R_{\mathrm{emp}}(f)=\min\limits _{f \in \mathcal{F}} \dfrac{1}{N}\sum\limits_{i=1}^{N} L\left(y_i,f(x_i)\right)
\end{equation}
\end{definition}

\begin{definition}
Structural risk
\begin{equation}
R_{\mathrm{smp}}(f)=\dfrac{1}{N}\sum\limits_{i=1}^{N} L\left(y_i,f(x_i)\right) +\lambda J(f)
\end{equation}
\end{definition}

\begin{definition}
SRM(Structural risk minimization)
\begin{equation}
\min\limits _{f \in \mathcal{F}} R_{\mathrm{srm}}(f)=\min\limits _{f \in \mathcal{F}} \dfrac{1}{N}\sum\limits_{i=1}^{N} L\left(y_i,f(x_i)\right) +\lambda J(f)
\end{equation}
\end{definition}


\subsection{Optimization}
Finally, we need a \textbf{training algorithm}(also called \textbf{learning algorithm}) to search among the classifiers in the the hypothesis space for the highest-scoring one. The choice of optimization technique is key to the \textbf{efficiency} of the model.

\section{Model Selection}
If data is plentiful,then on approach to avoid over-fitting is to use some of the some of the available data to train a range of models,or a given model with a range of values for its complexity parameters,and then to compare them on independent data,sometimes called a \textbf{Validation set},and select the one having the best predictive performance.If the model design is iterated many times using a limited size data set,then some over-fitting to the validation data can occur and so it may be necessary to keep aside a third \textbf{test set} on which the performance of the selected model is finally evaluated.

\subsubsection{Cross validation}
\label{sec:Cross-validation}
\begin{definition}
	\textbf{Cross validation}, sometimes called \emph{rotation estimation}, is a \emph{model validation} technique for assessing how the results of a statistical analysis will generalize to an independent data set\footnote{\url{http://en.wikipedia.org/wiki/Cross-validation_(statistics)}}.
\end{definition}

Common types of cross-validation:
\begin{enumerate}
	\item K-fold cross-validation. In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data.
	\item 2-fold cross-validation. Also, called simple cross-validation or holdout method. This is the simplest variation of k-fold cross-validation, k=2.
	\item Leave-one-out cross-validation(\emph{LOOCV}). k=M, the number of original samples.
\end{enumerate}
In many applications,however,the supply of data for training and testing will be limited.We wish to use as much of available data as possible for both training and validation set.One solution to this dilemma is to use \textbf{cross-validations}.One round of cross-validation involves partitioning a sample of data into complementary subsets, performing the analysis on one subset (called the training set), and validating the analysis on the other subset (called the validation set or testing set). To reduce variability, multiple rounds of cross-validation are performed using different partitions, and the validation results are averaged over the rounds.


\section{The Curse of Dimensionality}

\section{Some basic concepts}


\subsection{Parametric vs non-parametric models}


\subsection{A simple non-parametric classifier: K-nearest neighbours}

\subsubsection{Representation}
\begin{equation}
y=f(\vec{x})=\arg\min_{c}{\sum\limits_{\vec{x}_i \in N_k(\vec{x})} \mathbb{I}(y_i=c)}
\end{equation}
where $N_k(\vec{x})$ is the set of k points that are closest to point $\vec{x}$.

Usually use \textbf{k-d tree} to accelerate the process of finding k nearest points.

\subsubsection{Evaluation}
No training is needed.

\subsubsection{Optimization}
No training is needed.


\subsection{Overfitting}


\subsection{Model selection}
When we have a variety of models of different complexity (e.g., linear or logistic regression models with different degree polynomials, or KNN classifiers with different values ofK), how should we pick the right one? A natural approach is to compute the \textbf{misclassification rate} on the training set for each method.


